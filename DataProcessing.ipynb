{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chunder1/Google-Colab-/blob/main/DataProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing and Active Learning with Roboflow\n",
        "What this notebook does.\n",
        "1.) Turns a video input into a frame output\n",
        "  1a.) Video inpu path = unprocessed_Data @ \"video_dir\"\n",
        "  1b.) Video Output path = activeLearningDataDirectory @ \"output_dir\"\n",
        "2.) Uses a roboflow model and hosted inference endpoint uses active learning to improve model performance using the output frames."
      ],
      "metadata": {
        "id": "Uw5RnhoJzCx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.) Install Dependencies"
      ],
      "metadata": {
        "id": "6niMlvVG0LiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to install the required dependencies. Those dependencies are...\n",
        "1.) Open-CV\n",
        "2.) Roboflow\n",
        "3.) Inference SDK\n",
        "Run the code cell below."
      ],
      "metadata": {
        "id": "gYWlK8LP0i9H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LS2a5bbyniI"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "!pip install roboflow\n",
        "!pip install inference_sdk\n",
        "!pip install google-api-python-client\n",
        "!pip install os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.) Data Processing\n",
        "This script is for processing videos into frames and putting those frames into a directory called \"datasetDirectory\". Once these videos are split into images or frames the aforementioned directory will be accessed by the active learning portion of this notebook.\n",
        "\n",
        "First we need to mount google drive so that the input data can be accessed. The \"drive.flush_and_unmount()\" line is there to ensure that no errors are encountered if google drive was previously mounted."
      ],
      "metadata": {
        "id": "QOjfvSVFxczF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a.) Mount the Drive"
      ],
      "metadata": {
        "id": "Kt5sDcul0YE8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ4RQezPym11"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()  # This will unmount the drive\n",
        "drive.mount('/content/gdrive')  # Remount the drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b.) Process videos into frames\n",
        "The four important variables of this script are\n",
        "1.) \"video_dir\" or the path to where the videos are stored. Note: Make sure the file types in this folder end with .avi and that there are no nested folders.\n",
        "\n",
        "2.) \"output_dir\" or the destination directory for the output which in this case is frames or images.\n",
        "\n",
        "3.) \"gloabl_frame_count\" This should be whatever the number of the last frame outputted into the output_dir is plus 1\n",
        "\n",
        "4.) \"capture_interval\" This variable determines the frequnecy in which frames are captured. If the video is filmed at 30 frames per second and this is set to 1 then 30 frames per second would be captured or every frame. if it were set to 2 then every other frame would be captured. So on and so forth. We have it set to 10 so every tenth frame is captured or in other words 3 frames per second are captured."
      ],
      "metadata": {
        "id": "oJWLKtEt0Xq7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7QNawPOyhkr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Directory where your videos are stored\n",
        "video_dir = '/content/gdrive/MyDrive/unprocessed_Data'\n",
        "\n",
        "# The directory to store the output PNG images\n",
        "output_dir = '/content/gdrive/MyDrive/datasetDirectory'\n",
        "os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
        "\n",
        "# List all files in the video directory that match your naming convention\n",
        "video_files = [f for f in os.listdir(video_dir) if f.startswith(\"vid_\") and f.endswith(\".avi\")]\n",
        "\n",
        "# Global frame counter\n",
        "global_frame_count = 0\n",
        "\n",
        "# Process each video file\n",
        "for video_file in video_files:\n",
        "    video_path = os.path.join(video_dir, video_file)\n",
        "\n",
        "    # Open the video file\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Check if the video file is opened successfully\n",
        "    if not video.isOpened():\n",
        "        print(f\"Error opening video file: {video_file}\")\n",
        "        continue\n",
        "    else:\n",
        "        print(f\"Video file {video_file} opened successfully\")\n",
        "\n",
        "    # Read frames from the video and convert them to PNG images\n",
        "    frame_count = 0\n",
        "    capture_interval = 10\n",
        "    while video.isOpened():\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Only save every Nth frame (as defined by capture_interval)\n",
        "        if frame_count % capture_interval == 0:\n",
        "            # Use the global frame count in the filename to ensure uniqueness\n",
        "            output_path = os.path.join(output_dir, f'img_{global_frame_count:08d}.png')\n",
        "            cv2.imwrite(output_path, frame)\n",
        "            global_frame_count += 1\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release the video file\n",
        "    video.release()\n",
        "\n",
        "    print(f\"Total frames extracted from {video_file}: {frame_count}\")\n",
        "\n",
        "print(f\"Total frames extracted: {global_frame_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that all of the videos have been turned into images instead of using a hosted inference endpoint we are going to run this through a model hosted on roboflow but do it in this notebook. We will then create a file associated with that image that has the annotations from the inference."
      ],
      "metadata": {
        "id": "y1F_d_Pz2qhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.) Run Inference\n",
        "This portion of the notebook utilizes Roboflows hosted inference endpoint. The purpose of this is to be able to feed a massive dataset to the desired model while active learning is enabled."
      ],
      "metadata": {
        "id": "zbXUnbPJnU8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "from inference_sdk import InferenceHTTPClient\n",
        "import os\n",
        "from PIL import Image\n",
        "import requests\n",
        "from google.colab import drive\n",
        "\n",
        "folder_path = \"/content/gdrive/MyDrive/datasetDirectory\"  # Update this path to where your data is located\n",
        "\n",
        "# Initialize the Roboflow client\n",
        "CLIENT = InferenceHTTPClient(\n",
        "    api_url=\"http://detect.roboflow.com\",\n",
        "    api_key=\"###################\" # Roboflow API Key\n",
        ")\n",
        "\n",
        "# Iterate through each file in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check if the file is an image\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Perform inference on the image\n",
        "        result = CLIENT.infer(file_path, model_id=\"\") #Model_id to the project you want to access\n",
        "\n",
        "        # Print inference completion message for each image\n",
        "        print(f\"Inference Completed for {file_name}\")\n",
        "\n",
        "print(\"All inferences completed.\")"
      ],
      "metadata": {
        "id": "6w0Yo0kpn05r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oIdV1pajoASE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy9KB4EkKSArdq9zYjVlW3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
